{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf8d0f6f",
   "metadata": {},
   "source": [
    "## Checklist / TODO (short)\n",
    "- Collect ≥300 images (4:3, >=800x600). Organize into `data/train/` and `data/test/`.\n",
    "- Annotate each image into 64 cell labels (0=no object,1=ball,2=bat,3=stump) and save CSV with columns: `ImageFileName,TrainOrTest,c01..c64`.\n",
    "- Extract hand-crafted features per cell (color hist, edge density, HOG, LBP, moments).\n",
    "- Train baseline classifiers (RandomForest/SVM), evaluate, pick final model and save `model_<teamname>.pkl`.\n",
    "- Produce final predictions CSV and README describing sources & steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2197bb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: split image into 8x8 cells (assumes 800x600 input)\n",
    "def split_image_to_cells(img, n_rows=8, n_cols=8):\n",
    "    \"\"\"Return list of cells in row-major order.\n",
    "    Each cell is a sub-image (H x W x C). For 800x600 image the cell size will be 100x75 (width x height).\n",
    "    \"\"\"\n",
    "    h, w = img.shape[:2]\n",
    "    cell_h = h // n_rows\n",
    "    cell_w = w // n_cols\n",
    "    cells = []\n",
    "    for r in range(n_rows):\n",
    "        for c in range(n_cols):\n",
    "            y0, y1 = r * cell_h, (r + 1) * cell_h\n",
    "            x0, x1 = c * cell_w, (c + 1) * cell_w\n",
    "            cells.append(img[y0:y1, x0:x1].copy())\n",
    "    return cells\n",
    "\n",
    "# Small test (uncomment and provide a path to test)\n",
    "# img = cv2.imread('path/to/800x600_image.jpg')\n",
    "# cells = split_image_to_cells(img)\n",
    "# print(len(cells), cells[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cfdedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extractor (per cell) - compact, hand-crafted features\n",
    "from skimage.feature import hog, local_binary_pattern\n",
    "\n",
    "def extract_features_from_cell(cell, rgb_hist_bins=8, hog_orientations=9):\n",
    "    \"\"\"Return a 1D numpy array of features for one cell.\n",
    "    Features included:\n",
    "      - RGB hist (rgb_hist_bins per channel) -> 3*rgb_hist_bins\n",
    "      - HSV hue histogram (rgb_hist_bins) -> rgb_hist_bins\n",
    "      - Mean & std of grayscale -> 2\n",
    "      - Edge density (Canny) -> 1\n",
    "      - HOG (small slice to keep vector compact) -> 12 (approx)\n",
    "      - LBP histogram (P=8, R=1) -> 8\n",
    "    \"\"\"\n",
    "    feats = []\n",
    "    # Ensure cell has correct dtype\n",
    "    cell = cell.astype(np.uint8)\n",
    "    # RGB histograms\n",
    "    for ch in range(3):\n",
    "        hist = cv2.calcHist([cell], [ch], None, [rgb_hist_bins], [0,256]).flatten()\n",
    "        hist = hist / (hist.sum() + 1e-9)\n",
    "        feats.extend(hist.tolist())\n",
    "    # HSV hue hist (use Hue channel)\n",
    "    hsv = cv2.cvtColor(cell, cv2.COLOR_BGR2HSV)\n",
    "    hue = hsv[:,:,0]\n",
    "    hhist = cv2.calcHist([hue], [0], None, [rgb_hist_bins], [0,180]).flatten()\n",
    "    hhist = hhist / (hhist.sum() + 1e-9)\n",
    "    feats.extend(hhist.tolist())\n",
    "    # Grayscale stats\n",
    "    gray = cv2.cvtColor(cell, cv2.COLOR_BGR2GRAY)\n",
    "    feats.append(float(gray.mean()))\n",
    "    feats.append(float(gray.std()))\n",
    "    # Edge density (Canny)\n",
    "    edges = cv2.Canny(gray, 100, 200)\n",
    "    feats.append(float(edges.sum()) / (gray.size + 1e-9))\n",
    "    # HOG (take first 12 elements to keep compact)\n",
    "    hog_vec = hog(gray, orientations=hog_orientations, pixels_per_cell=(16,16), cells_per_block=(1,1), feature_vector=True)\n",
    "    hog_take = hog_vec[:12] if len(hog_vec) >= 12 else np.pad(hog_vec, (0, max(0, 12-len(hog_vec))))\n",
    "    feats.extend(hog_take.tolist())\n",
    "    # LBP (P=8, R=1) and small histogram of radius patterns\n",
    "    lbp = local_binary_pattern(gray, P=8, R=1, method='uniform')\n",
    "    # histogram bins: 0..8 (9 bins) but we'll use 8 bins (drop last) to keep size small\n",
    "    lbp_hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, 11), range=(0,10))\n",
    "    lbp_hist = lbp_hist / (lbp_hist.sum() + 1e-9)\n",
    "    feats.extend(lbp_hist[:8].tolist())\n",
    "    return np.array(feats, dtype=float)\n",
    "\n",
    "# Example: extract features for all cells of one image\n",
    "def extract_features_for_image(img_path):\n",
    "    img = cv2.imread(str(img_path))\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(f'Image not found: {img_path}')\n",
    "    # Resize to 800x600 if needed (only downscale allowed as per instructions)\n",
    "    h, w = img.shape[:2]\n",
    "    if w < 800 or h < 600:\n",
    "        raise ValueError('Image smaller than 800x600 — do not scale up. Skip this image.')\n",
    "    if (w, h) != (800, 600):\n",
    "        img = cv2.resize(img, (800,600), interpolation=cv2.INTER_AREA)\n",
    "    cells = split_image_to_cells(img)\n",
    "    feats = [extract_features_from_cell(c) for c in cells]\n",
    "    return np.vstack(feats)  # shape: (64, n_features)\n",
    "\n",
    "# Quick usage example (uncomment and set path)\n",
    "# feats = extract_features_for_image('data/train/IMG_001.jpg')\n",
    "# print('features per cell shape:', feats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240ecaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a small helper function to process a directory and write per-cell feature CSV\n",
    "def create_features_csv_for_dir(img_dir, out_csv_path, tag='train'):\n",
    "    rows = []\n",
    "    for img_file in sorted(Path(img_dir).glob('*')):\n",
    "        try:\n",
    "            feats = extract_features_for_image(img_file)  # 64 x n_features\n",
    "        except Exception as e:\n",
    "            print('Skipping', img_file, '->', e)\n",
    "            continue\n",
    "        # flatten per-image as 64 blocks of features (optionally keep per-cell features separate)\n",
    "        # For training you'll want per-cell rows: one row per cell with ImageFileName, cell_index, features...\n",
    "        for i in range(feats.shape[0]):\n",
    "            row = { 'ImageFileName': img_file.name, 'TrainOrTest': tag, 'cell_index': i+1 }\n",
    "            # append feature columns\n",
    "            for j, val in enumerate(feats[i]):\n",
    "                row[f'f{j+1}'] = val\n",
    "            rows.append(row)\n",
    "    df_out = pd.DataFrame(rows)\n",
    "    df_out.to_csv(out_csv_path, index=False)\n",
    "    print('Wrote', out_csv_path, 'rows=', len(df_out))\n",
    "\n",
    "# Example usage (uncomment to run)\n",
    "# create_features_csv_for_dir(TRAIN_DIR, OUTPUT_DIR / 'train_cell_features.csv', tag='train')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89533f9",
   "metadata": {},
   "source": [
    "## Next steps (suggested)\n",
    "- Create `data/train/` and `data/test/` and put images in place. Do not scale up images smaller than 800x600.\n",
    "- Use the `create_features_csv_for_dir` to extract per-cell features for the train set, then annotate labels in a CSV and join features with labels for training.\n",
    "- Train classifiers (RandomForest/SVM) on the per-cell features; evaluate and tune.\n",
    "- When ready, save the model with `joblib.dump(clf, 'model_<teamname>.pkl')` and produce the final predictions CSV in the required format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce1dd35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing icrawler...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "`download_and_prepare` function not found. Ensure you ran the earlier cells that define it.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 26\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 26\u001b[0m     download_and_prepare\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNameError\u001b[39;00m:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'download_and_prepare' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 28\u001b[0m\n\u001b[0;32m     26\u001b[0m     download_and_prepare\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNameError\u001b[39;00m:\n\u001b[1;32m---> 28\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNameError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`download_and_prepare` function not found. Ensure you ran the earlier cells that define it.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Define sample classes and run downloader with small counts\u001b[39;00m\n\u001b[0;32m     31\u001b[0m classes \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbat\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcricket bat\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mball\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcricket ball\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstump\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcricket stumps\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno_object\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrass background\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     36\u001b[0m }\n",
      "\u001b[1;31mNameError\u001b[0m: `download_and_prepare` function not found. Ensure you ran the earlier cells that define it."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29452bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
