{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1a38efb",
   "metadata": {},
   "source": [
    "# Note: Advanced functions like melt, pivot table won't be there for the mid-term exam. It is good to know it and it may come in the end semester and will be useful for your project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8ae290",
   "metadata": {},
   "source": [
    "# Pandas Questions\n",
    "\n",
    "This notebook contains **6 diverse, scenario-based Pandas problems**.  \n",
    "Each problem includes:\n",
    "- Clear instructions on how to construct the DataFrame\n",
    "- A hint pointing to useful Pandas functions\n",
    "- A short explanation of what the key function(s) do and example usage\n",
    "\n",
    "**Setup:** Run the import cell before attempting the questions.\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c264d4",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Run the import cell below before attempting the questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f59d1e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Only pandas is imported in this notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087ced2e",
   "metadata": {},
   "source": [
    "## Q1 — Grouping, aggregation and filtering\n",
    "\n",
    "**Instructions (DataFrame construction):**\n",
    "Create `df_sales` with columns: `OrderID`, `CustomerID`, `Product`, `Units`, `UnitPrice`, `OrderDate`.\n",
    "- Create ~12 rows across 4 customers (CustomerID 1–4) and 5 products (P1–P5).\n",
    "- `OrderDate` as strings like `'2025-01-03'`.\n",
    "\n",
    "**Task:**\n",
    "1. Add `Amount = Units * UnitPrice`.\n",
    "2. Compute total `Amount` per `CustomerID`.\n",
    "3. Show only customers with total > 300, sorted descending.\n",
    "\n",
    "**Hint:** Use `.groupby()` and `.sum()` after creating the `Amount` column. You can filter using boolean indexing.\n",
    "\n",
    "**Function explanation — `groupby`:**\n",
    "`groupby()` splits the DataFrame into groups based on column values. You then apply aggregation functions (e.g., `sum`, `mean`, `count`) to each group. Example:\n",
    "```python\n",
    "df.groupby('CustomerID')['Amount'].sum()\n",
    "```\n",
    "This returns total `Amount` per `CustomerID`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a9b1641a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    orderId  customerId  productId  units  price  orderDate  Amount\n",
      "0         1           1          1      1     10 2023-01-01      10\n",
      "1         2           1          1      2     20 2023-01-02      40\n",
      "2         3           1          2      1     30 2023-01-03      30\n",
      "3         4           1          2      2     40 2023-01-04      80\n",
      "4         5           2          3      1     50 2023-01-05      50\n",
      "5         6           2          3      2     60 2023-01-06     120\n",
      "6         7           2          1      1     10 2023-01-07      10\n",
      "7         8           2          1      2     20 2023-01-08      40\n",
      "8         9           3          2      1     30 2023-01-09      30\n",
      "9        10           3          2      2     40 2023-01-10      80\n",
      "10       11           3          3      1     50 2023-01-11      50\n",
      "11       12           3          3      2     60 2023-01-12     120\n",
      "Sum by Customer ID  customerId\n",
      "1    160\n",
      "2    220\n",
      "3    280\n",
      "Name: Amount, dtype: int64\n",
      "Result of group by  customerId\n",
      "1    160\n",
      "2    220\n",
      "3    280\n",
      "Name: Amount, dtype: int64\n",
      "customerId\n",
      "3    280\n",
      "2    220\n",
      "Name: Amount, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE: build df_sales and solve Q1\n",
    "\n",
    "df_sales=pd.DataFrame({\n",
    "    'orderId': range(1,13),\n",
    "    'customerId': [1,1,1,1,2,2,2,2,3,3,3,3],\n",
    "    'productId': [1,1,2,2,3,3,1,1,2,2,3,3],\n",
    "    'units': [1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2],\n",
    "    'price': [10, 20, 30, 40, 50, 60, 10, 20, 30, 40, 50, 60],\n",
    "    'orderDate': pd.date_range(start='2023-01-01', periods=12, freq='D')\n",
    "})\n",
    "df_sales['Amount']=df_sales['units'] * df_sales['price']\n",
    "\n",
    "print(df_sales)\n",
    "print(\"Sum by Customer ID \" ,df_sales.groupby('customerId')['Amount'].sum())\n",
    "\n",
    "#Show only customers with total > 300, sorted descending.\n",
    "result = df_sales.groupby('customerId')['Amount'].sum()\n",
    "\n",
    "print(\"Result of group by \", result)\n",
    "result = result[result > 200].sort_values(ascending=False)\n",
    "print(result)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a919d5",
   "metadata": {},
   "source": [
    "## Q2 — Join (merge) and derived boolean column\n",
    "\n",
    "**Instructions (DataFrame construction):**\n",
    "Create `df_employees` with `EmpID`, `Name`, `DeptID` (6 rows). Create `df_depts` with `DeptID`, `DeptName`, `Manager` (3 rows).\n",
    "\n",
    "**Task:**\n",
    "1. Merge into `df_full` that includes DeptName and Manager.\n",
    "2. Create `IsManagedByAlice` == True when Manager == 'Alice'.\n",
    "3. Show counts of employees per DeptName and number managed by Alice.\n",
    "\n",
    "**Hint:** Use `merge()` to join the tables and boolean comparison `==` to produce the new column.\n",
    "\n",
    "**Function explanation — `merge`:**\n",
    "`merge()` combines two DataFrames on a key column (like SQL JOIN). Example:\n",
    "```python\n",
    "df_employees.merge(df_depts, on='DeptID', how='left')\n",
    "```\n",
    "This adds department details to each employee row. For booleans, compare a column to a value:\n",
    "```python\n",
    "df['IsManagedByAlice'] = df['Manager'] == 'Alice'\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "21ef244c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   empId  empName  deptId deptName deptManager  IsManagedByAlice\n",
      "0      1    Alice       1       HR       Alice              True\n",
      "1      2      Bob       2    Sales         Bob             False\n",
      "2      3  Charlie       1       HR       Alice              True\n",
      "3      4    David       3       IT     Charlie             False\n",
      "4      5      Eva       2    Sales         Bob             False\n",
      "5      6    Frank       1       HR       Alice              True\n",
      "6      7    Grace       3       IT     Charlie             False\n",
      "7      8   Hannah       2    Sales         Bob             False\n",
      "8      9      Ian       1       HR       Alice              True\n",
      "9     10     Jane       3       IT     Charlie             False\n",
      "Dept with more than 3 employees  deptId\n",
      "1    4\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE: build df_employees, df_depts and solve Q2\n",
    "\n",
    "df_employees = pd.DataFrame({\n",
    "    'empId': range(1,11),\n",
    "    'empName': ['Alice', 'Bob', 'Charlie', 'David', 'Eva', 'Frank', 'Grace', 'Hannah', 'Ian', 'Jane'],\n",
    "    'deptId': [1, 2, 1, 3, 2, 1, 3, 2, 1, 3]})\n",
    "\n",
    "#print(df_employees)\n",
    "\n",
    "df_depts = pd.DataFrame({\n",
    "    'deptId': [1, 2, 3],\n",
    "    'deptName': ['HR', 'Sales', 'IT'],\n",
    "    'deptManager':['Alice','Bob','Charlie']\n",
    "})\n",
    "\n",
    "#print(df_depts)\n",
    "\n",
    "df_full=df_employees.merge(df_depts, on='deptId', how='left')\n",
    "\n",
    "df_full['IsManagedByAlice']=  (df_full['deptManager'] =='Alice')\n",
    "print(df_full)\n",
    "\n",
    "groupedByDept=df_full.groupby('deptId').size()\n",
    "\n",
    "#print dept names having more than 3 employees\n",
    "result2 = df_full.groupby('deptId').size()\n",
    "result2 = result2[result2 > 3]\n",
    "print(\"Dept with more than 3 employees \", result2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d6a67b",
   "metadata": {},
   "source": [
    "## Q3 — Reshape: melt and pivot\n",
    "\n",
    "**Instructions (DataFrame construction):**\n",
    "Create `df_quarterly` (wide) with columns `Company`, `Q1`, `Q2`, `Q3`, `Q4` for 5 companies (numeric revenue).\n",
    "\n",
    "**Task:**\n",
    "1. Use `melt` to convert to long format (`Company`, `Quarter`, `Revenue`).\n",
    "2. Pivot back to wide using `pivot_table`.\n",
    "3. Compute each company's annual revenue and append as column to the pivot result.\n",
    "\n",
    "**Hint:** `pd.melt()` and `pivot_table()` are complementary — melt turns wide -> long; pivot_table (or pivot) can aggregate and reshape long -> wide.\n",
    "\n",
    "**Function explanation — `melt` and `pivot_table`:**\n",
    "- `melt(df, id_vars=[...], value_vars=[...])` turns columns into rows, useful for tidy/long-format data.\n",
    "- `pivot_table(index=..., columns=..., values=..., aggfunc=...)` reshapes long data to wide and allows aggregation. Example:\n",
    "```python\n",
    "df_long = pd.melt(df_quarterly, id_vars=['Company'], value_vars=['Q1','Q2','Q3','Q4'], var_name='Quarter', value_name='Revenue')\n",
    "df_wide = df_long.pivot_table(index='Company', columns='Quarter', values='Revenue')\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a649d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE: build df_quarterly and solve Q3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b151db",
   "metadata": {},
   "source": [
    "## Q4 — Time series: rolling mean and resample\n",
    "\n",
    "**Instructions (DataFrame construction):**\n",
    "Create `df_temp` with daily `Date` (as strings) from '2025-03-01' to '2025-03-10' and a `Temperature` float column.\n",
    "\n",
    "**Task:**\n",
    "1. Convert `Date` to datetime and set as index.\n",
    "2. Add `Temp_3d_avg` as 3-day rolling mean of Temperature.\n",
    "3. Resample to weekly frequency and report mean temperature per week.\n",
    "\n",
    "**Hint:** Convert dates with `pd.to_datetime()`, set as index, then use `.rolling()` and `.resample()`.\n",
    "\n",
    "**Function explanation — `rolling` and `resample`:**\n",
    "- `rolling(window=n).mean()` computes a moving average over `n` rows (good for smoothing). Example: `df['Temperature'].rolling(window=3).mean()`.\n",
    "- `resample('W')` groups data into fixed time windows (here weekly); you can then call aggregation like `.mean()` to get weekly averages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22c1d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            temprature  temprature_3d_avg\n",
      "date                                     \n",
      "2025-03-02   31.000000                NaN\n",
      "2025-03-09   27.142857          28.142857\n",
      "2025-03-16   23.000000          24.000000\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE: build df_temp and solve Q4\n",
    "\n",
    "\n",
    "df_temp=pd.DataFrame({\n",
    "    'date':pd.date_range(start='2025-03-01', periods=10, freq='D'),\n",
    "    'temprature':[30,32,31,29,28,27,26,25,24,23]\\\n",
    "})\n",
    "\n",
    "df_temp['date']=pd.to_datetime(df_temp['date'])\n",
    "\n",
    "df_temp.set_index('date', inplace=True)\n",
    "\n",
    "df_temp['temprature_3d_avg']=df_temp['temprature'].rolling(window=3).mean()\n",
    "\n",
    "resampled_df = df_temp.resample('W').mean()\n",
    "\n",
    "print(resampled_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2312a4",
   "metadata": {},
   "source": [
    "## Q5 — Missing data handling and imputation\n",
    "\n",
    "**Instructions (DataFrame construction):**\n",
    "Create `df_products` with columns `SKU`, `Category`, `Price`, `Stock` (8 rows). Include some `NaN` values in `Price` and `Stock`. At least 3 categories.\n",
    "\n",
    "**Task:**\n",
    "1. Show number of missing values per column.\n",
    "2. Fill missing `Price` with median `Price` of the same `Category` and missing `Stock` with 0.\n",
    "3. After imputation, show SKUs where `Stock == 0` or `Price > 100`.\n",
    "\n",
    "**Hint:** Use `isna()`, `fillna()` and `groupby().transform()` to fill per-group values.\n",
    "\n",
    "**Function explanation — `isna`, `fillna`, and `transform`:**\n",
    "- `isna()` identifies missing values. `df.isna().sum()` gives counts.\n",
    "- `fillna(value)` replaces missing values with `value` (or use `inplace=True` to modify the DataFrame).\n",
    "- `groupby(...).transform()` applies a function per group and returns a Series aligned with the original DataFrame, useful for filling missing values using group statistics, e.g.:\n",
    "```python\n",
    "df['Price'] = df.groupby('Category')['Price'].transform(lambda x: x.fillna(x.median()))\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2524908",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e8174ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  SKU     Category  Price  Stock\n",
      "0  A1  Electronics  100.0   50.0\n",
      "1  A2  Electronics  200.0   60.0\n",
      "2  A3    Furniture  300.0   70.0\n",
      "3  A4    Furniture  200.0    0.0\n",
      "4  A5     Clothing  200.0    0.0\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE: build df_products and solve Q5\n",
    "\n",
    "\n",
    "\n",
    "df_products=pd.DataFrame({'SKU':['A1','A2','A3','A4','A5'],\n",
    "                          'Category':['Electronics','Electronics','Furniture','Furniture','Clothing'],\n",
    "                          'Price':[100,200,300,float('NaN'),float('NaN')],\n",
    "                          'Stock':[50,60,70,float('NaN'),float('NaN')]})\n",
    "\n",
    "\n",
    "df_products.isna().sum()\n",
    "\n",
    "df_products.fillna({'Price':df_products['Price'].mean(), 'Stock':0}, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "df_products['Price'] = df_products.groupby('Category')['Price'].transform(lambda x: x.fillna(x.median()))\n",
    "print(df_products)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3f96f8",
   "metadata": {},
   "source": [
    "## Q6 — Apply/custom logic and string operations\n",
    "\n",
    "**Instructions (DataFrame construction):**\n",
    "Create `df_courses` with columns `CourseID`, `Title`, `Enrolled`, `StartDate` for 6 courses. Some titles should contain 'Intro' or 'Advanced'. `StartDate` as strings.\n",
    "\n",
    "**Task:**\n",
    "1. Create `Level`: 'Beginner' if Title contains 'Intro', 'Advanced' if contains 'Advanced', else 'Intermediate'. Use `apply` or vectorized string ops.\n",
    "2. Create `StartMonth` derived from `StartDate`.\n",
    "3. Show average `Enrolled` per `Level`.\n",
    "\n",
    "**Hint:** Use `.str.contains()` for text checks and either `.apply()` or `np.where` for conditional column creation. Convert `StartDate` to datetime to extract month.\n",
    "\n",
    "**Function explanation — `str.contains`, `apply`, and datetime accessor `.dt`:**\n",
    "- `df['Title'].str.contains('Intro')` returns a boolean Series marking rows where 'Intro' appears.\n",
    "- `apply()` runs a function row- or column-wise; useful for custom logic but can be slower than vectorized ops.\n",
    "- After converting `StartDate` to datetime (`pd.to_datetime()`), use `.dt.month` to get the month number. Example:\n",
    "```python\n",
    "df['StartDate'] = pd.to_datetime(df['StartDate'])\n",
    "df['StartMonth'] = df['StartDate'].dt.month\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a298788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   courseId            Title  enrolled  startDate         Level  startMonth\n",
      "1         2  Advanced Python        25 2023-02-15      Advanced           2\n",
      "3         4      Advanced ML        15 2023-04-25      Advanced           4\n",
      "0         1     Intro Python        30 2023-01-10      Beginner           1\n",
      "2         3         Intro ML        20 2023-03-20      Beginner           3\n",
      "4         5     Data Science        10 2023-05-30  Intermediate           5\n",
      "5         6               AI         5 2023-06-05  Intermediate           6\n",
      "Level\n",
      "Advanced        20.0\n",
      "Beginner        25.0\n",
      "Intermediate     7.5\n",
      "Name: enrolled, dtype: float64\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE: build df_courses and solve Q6\n",
    "df_courses=pd.DataFrame({\n",
    "    'courseId':[1,2,3,4,5,6],\n",
    "    'Title':['Intro Python','Advanced Python','Intro ML','Advanced ML','Data Science','AI'],\n",
    "    \"enrolled\":[30,25,20,15,10,5],\n",
    "    'startDate':pd.to_datetime(['2023-01-10','2023-02-15','2023-03-20','2023-04-25','2023-05-30','2023-06-05'])\n",
    "})\n",
    "\n",
    "df_courses['Level']= df_courses['Title'].apply(lambda x: level_from_title(x))\n",
    "\n",
    "\n",
    "df_courses['startDate']=pd.to_datetime(df_courses['startDate'])\n",
    "\n",
    "df_courses['startMonth']=df_courses['startDate'].dt.month\n",
    "\n",
    "print(df_courses.sort_values(by='Level'))\n",
    "\n",
    "avg=df_courses.groupby('Level')['enrolled'].mean()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def level_from_title(title):\n",
    "    if 'Intro' in title :\n",
    "        return 'Beginner'\n",
    "    elif 'Advanced' in title:\n",
    "        return 'Advanced'\n",
    "    else:\n",
    "        return 'Intermediate'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808bebf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
