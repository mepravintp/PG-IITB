{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "016b4274",
   "metadata": {},
   "source": [
    "# Diverse Pandas Quiz — Questions & Solutions\n",
    "\n",
    "This notebook contains the 6 problems followed immediately by their full, runnable solutions.\n",
    "Run the import cell below first (single import for the whole notebook).\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2edea59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Single import cell - pandas only\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814d274a",
   "metadata": {},
   "source": [
    "## Q1 — Grouping, aggregation and filtering\n",
    "\n",
    "**Instructions (DataFrame construction):**\n",
    "Create `df_sales` with columns: `OrderID`, `CustomerID`, `Product`, `Units`, `UnitPrice`, `OrderDate`.\n",
    "- ~12 rows across 4 customers (CustomerID 1–4) and 5 products (P1–P5).\n",
    "- `OrderDate` as strings like `'2025-01-03'`.\n",
    "\n",
    "**Task:**\n",
    "1. Add `Amount = Units * UnitPrice`.\n",
    "2. Compute total `Amount` per `CustomerID`.\n",
    "3. Show only customers with total > 300, sorted descending.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32e989c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution for Q1\n",
    "df_sales = pd.DataFrame([\n",
    "    {'OrderID':101,'CustomerID':1,'Product':'P1','Units':5,'UnitPrice':20,'OrderDate':'2025-01-03'},\n",
    "    {'OrderID':102,'CustomerID':2,'Product':'P2','Units':3,'UnitPrice':50,'OrderDate':'2025-01-04'},\n",
    "    {'OrderID':103,'CustomerID':1,'Product':'P3','Units':2,'UnitPrice':120,'OrderDate':'2025-01-05'},\n",
    "    {'OrderID':104,'CustomerID':3,'Product':'P2','Units':10,'UnitPrice':15,'OrderDate':'2025-01-06'},\n",
    "    {'OrderID':105,'CustomerID':4,'Product':'P4','Units':1,'UnitPrice':300,'OrderDate':'2025-01-06'},\n",
    "    {'OrderID':106,'CustomerID':2,'Product':'P1','Units':7,'UnitPrice':18,'OrderDate':'2025-01-07'},\n",
    "    {'OrderID':107,'CustomerID':3,'Product':'P5','Units':4,'UnitPrice':40,'OrderDate':'2025-01-08'},\n",
    "    {'OrderID':108,'CustomerID':1,'Product':'P2','Units':6,'UnitPrice':30,'OrderDate':'2025-01-09'},\n",
    "    {'OrderID':109,'CustomerID':4,'Product':'P3','Units':2,'UnitPrice':120,'OrderDate':'2025-01-10'},\n",
    "    {'OrderID':110,'CustomerID':2,'Product':'P4','Units':1,'UnitPrice':250,'OrderDate':'2025-01-10'},\n",
    "    {'OrderID':111,'CustomerID':3,'Product':'P1','Units':8,'UnitPrice':20,'OrderDate':'2025-01-11'},\n",
    "    {'OrderID':112,'CustomerID':1,'Product':'P5','Units':3,'UnitPrice':60,'OrderDate':'2025-01-12'},\n",
    "])\n",
    "\n",
    "# 1. Add Amount column\n",
    "df_sales['Amount'] = df_sales['Units'] * df_sales['UnitPrice']\n",
    "\n",
    "# 2. Total per CustomerID\n",
    "total_by_cust = df_sales.groupby('CustomerID', as_index=False)['Amount'].sum()\n",
    "\n",
    "# 3. Filter and sort\n",
    "result_q1 = total_by_cust[total_by_cust['Amount'] > 300].sort_values('Amount', ascending=False)\n",
    "\n",
    "print('--- df_sales (first 8 rows) ---') \n",
    "print(df_sales.head(8).to_string(index=False))\n",
    "print('\\n--- Total Amount per Customer ---')\n",
    "print(total_by_cust.to_string(index=False))\n",
    "print('\\n--- Customers with total > 300 ---')\n",
    "print(result_q1.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784c6a1e",
   "metadata": {},
   "source": [
    "## Q2 — Join (merge) and derived boolean column\n",
    "\n",
    "**Instructions (DataFrame construction):**\n",
    "Create `df_employees` with `EmpID`, `Name`, `DeptID` (6 rows). Create `df_depts` with `DeptID`, `DeptName`, `Manager` (3 rows).\n",
    "\n",
    "**Task:**\n",
    "1. Merge into `df_full` that includes DeptName and Manager.\n",
    "2. Create `IsManagedByAlice` == True when Manager == 'Alice'.\n",
    "3. Show counts of employees per DeptName and number managed by Alice.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f1f700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution for Q2\n",
    "df_employees = pd.DataFrame([\n",
    "    {'EmpID':1,'Name':'Ravi','DeptID':10},\n",
    "    {'EmpID':2,'Name':'Meera','DeptID':20},\n",
    "    {'EmpID':3,'Name':'Ajay','DeptID':10},\n",
    "    {'EmpID':4,'Name':'Priya','DeptID':30},\n",
    "    {'EmpID':5,'Name':'Sameer','DeptID':20},\n",
    "    {'EmpID':6,'Name':'Anita','DeptID':30},\n",
    "])\n",
    "\n",
    "df_depts = pd.DataFrame([\n",
    "    {'DeptID':10,'DeptName':'Data','Manager':'Alice'},\n",
    "    {'DeptID':20,'DeptName':'Infra','Manager':'Bob'},\n",
    "    {'DeptID':30,'DeptName':'HR','Manager':'Alice'},\n",
    "])\n",
    "\n",
    "# 1. Merge\n",
    "df_full = df_employees.merge(df_depts, on='DeptID', how='left')\n",
    "\n",
    "# 2. Derived boolean\n",
    "df_full['IsManagedByAlice'] = df_full['Manager'] == 'Alice'\n",
    "\n",
    "# 3. Counts per department and managed by Alice\n",
    "counts = df_full.groupby('DeptName', as_index=False)['EmpID'].count().rename(columns={'EmpID':'EmployeeCount'})\n",
    "managed_by_alice = df_full[df_full['IsManagedByAlice']].groupby('DeptName', as_index=False)['EmpID'].count().rename(columns={'EmpID':'ManagedByAlice'})\n",
    "summary = counts.merge(managed_by_alice, on='DeptName', how='left').fillna(0)\n",
    "summary['ManagedByAlice'] = summary['ManagedByAlice'].astype(int)\n",
    "\n",
    "print('--- Merged df_full ---')\n",
    "print(df_full.to_string(index=False))\n",
    "print('\\n--- Employee counts and managed by Alice ---')\n",
    "print(summary.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4638f33b",
   "metadata": {},
   "source": [
    "## Q3 — Reshape: melt and pivot\n",
    "\n",
    "**Instructions (DataFrame construction):**\n",
    "Create `df_quarterly` (wide) with columns `Company`, `Q1`, `Q2`, `Q3`, `Q4` for 5 companies (numeric revenue).\n",
    "\n",
    "**Task:**\n",
    "1. Use `melt` to convert to long format (`Company`, `Quarter`, `Revenue`).\n",
    "2. Pivot back to wide using `pivot_table`.\n",
    "3. Compute each company's annual revenue and append as column to the pivot result.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565e215c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution for Q3\n",
    "df_quarterly = pd.DataFrame([\n",
    "    {'Company':'C1','Q1':120,'Q2':130,'Q3':125,'Q4':140},\n",
    "    {'Company':'C2','Q1':200,'Q2':210,'Q3':190,'Q4':205},\n",
    "    {'Company':'C3','Q1':95,'Q2':100,'Q3':110,'Q4':105},\n",
    "    {'Company':'C4','Q1':150,'Q2':160,'Q3':155,'Q4':165},\n",
    "    {'Company':'C5','Q1':80,'Q2':90,'Q3':85,'Q4':95},\n",
    "])\n",
    "\n",
    "# 1. Melt to long format\n",
    "df_long = df_quarterly.melt(id_vars=['Company'], value_vars=['Q1','Q2','Q3','Q4'], var_name='Quarter', value_name='Revenue')\n",
    "\n",
    "# 2. Pivot back to wide\n",
    "df_pivot = df_long.pivot_table(index='Company', columns='Quarter', values='Revenue').reset_index()\n",
    "\n",
    "# 3. Annual revenue\n",
    "df_pivot['Annual'] = df_pivot[['Q1','Q2','Q3','Q4']].sum(axis=1)\n",
    "\n",
    "print('--- Long format (first 8 rows) ---')\n",
    "print(df_long.head(8).to_string(index=False))\n",
    "print('\\n--- Pivoted back to wide with Annual ---')\n",
    "print(df_pivot.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bc3039",
   "metadata": {},
   "source": [
    "## Q4 — Time series: rolling mean and resample\n",
    "\n",
    "**Instructions (DataFrame construction):**\n",
    "Create `df_temp` with daily `Date` (as strings) from '2025-03-01' to '2025-03-10' and a `Temperature` float column.\n",
    "\n",
    "**Task:**\n",
    "1. Convert `Date` to datetime and set as index.\n",
    "2. Add `Temp_3d_avg` as 3-day rolling mean of Temperature.\n",
    "3. Resample to weekly frequency and report mean temperature per week.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1867ad95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution for Q4\n",
    "dates = ['2025-03-01','2025-03-02','2025-03-03','2025-03-04','2025-03-05','2025-03-06','2025-03-07','2025-03-08','2025-03-09','2025-03-10']\n",
    "temps = [25.2, 24.8, 26.1, 27.0, 26.5, 25.0, 24.0, 23.5, 24.8, 25.6]\n",
    "\n",
    "df_temp = pd.DataFrame({'Date': dates, 'Temperature': temps})\n",
    "\n",
    "# 1. Convert to datetime and set index\n",
    "df_temp['Date'] = pd.to_datetime(df_temp['Date'])\n",
    "df_temp = df_temp.set_index('Date')\n",
    "\n",
    "# 2. 3-day rolling average\n",
    "df_temp['Temp_3d_avg'] = df_temp['Temperature'].rolling(window=3, min_periods=1).mean()\n",
    "\n",
    "# 3. Weekly resample mean\n",
    "weekly_mean = df_temp['Temperature'].resample('W').mean()\n",
    "\n",
    "print('--- Daily with 3-day rolling average ---')\n",
    "print(df_temp.to_string())\n",
    "print('\\n--- Weekly mean temperature ---')\n",
    "print(weekly_mean.to_string())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc5aa19",
   "metadata": {},
   "source": [
    "## Q5 — Missing data handling and imputation\n",
    "\n",
    "**Instructions (DataFrame construction):**\n",
    "Create `df_products` with columns `SKU`, `Category`, `Price`, `Stock` (8 rows). Include some `NaN` values in `Price` and `Stock`. At least 3 categories.\n",
    "\n",
    "**Task:**\n",
    "1. Show number of missing values per column.\n",
    "2. Fill missing `Price` with median `Price` of the same `Category` and missing `Stock` with 0.\n",
    "3. After imputation, show SKUs where `Stock == 0` or `Price > 100`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9eb549a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution for Q5\n",
    "df_products = pd.DataFrame([\n",
    "    {'SKU':'S1','Category':'Electronics','Price':120.0,'Stock':10},\n",
    "    {'SKU':'S2','Category':'Electronics','Price':None,'Stock':5},\n",
    "    {'SKU':'S3','Category':'Home','Price':45.0,'Stock':None},\n",
    "    {'SKU':'S4','Category':'Home','Price':55.0,'Stock':8},\n",
    "    {'SKU':'S5','Category':'Clothing','Price':None,'Stock':2},\n",
    "    {'SKU':'S6','Category':'Clothing','Price':80.0,'Stock':None},\n",
    "    {'SKU':'S7','Category':'Electronics','Price':200.0,'Stock':1},\n",
    "    {'SKU':'S8','Category':'Home','Price':None,'Stock':None},\n",
    "])\n",
    "\n",
    "# 1. Missing counts\n",
    "missing_counts = df_products.isna().sum()\n",
    "\n",
    "# 2. Impute Price by category median\n",
    "df_imputed = df_products.copy()\n",
    "df_imputed['Price'] = df_imputed.groupby('Category')['Price'].transform(lambda x: x.fillna(x.median()))\n",
    "df_imputed['Stock'] = df_imputed['Stock'].fillna(0)\n",
    "\n",
    "# 3. SKUs where Stock == 0 or Price > 100\n",
    "condition = (df_imputed['Stock'] == 0) | (df_imputed['Price'] > 100)\n",
    "skus_selected = df_imputed.loc[condition]\n",
    "\n",
    "print('--- Missing value counts before imputation ---')\n",
    "print(missing_counts.to_string())\n",
    "print('\\n--- After imputation ---')\n",
    "print(df_imputed.to_string(index=False))\n",
    "print('\\n--- SKUs with Stock == 0 or Price > 100 ---')\n",
    "print(skus_selected.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad1e422",
   "metadata": {},
   "source": [
    "## Q6 — Apply/custom logic and string operations\n",
    "\n",
    "**Instructions (DataFrame construction):**\n",
    "Create `df_courses` with columns `CourseID`, `Title`, `Enrolled`, `StartDate` for 6 courses. Some titles should contain 'Intro' or 'Advanced'. `StartDate` as strings.\n",
    "\n",
    "**Task:**\n",
    "1. Create `Level`: 'Beginner' if Title contains 'Intro', 'Advanced' if contains 'Advanced', else 'Intermediate'. Use `apply` or vectorized string ops.\n",
    "2. Create `StartMonth` derived from `StartDate`.\n",
    "3. Show average `Enrolled` per `Level`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394e1538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution for Q6\n",
    "df_courses = pd.DataFrame([\n",
    "    {'CourseID':'C101','Title':'Intro to Python','Enrolled':120,'StartDate':'2025-02-01'},\n",
    "    {'CourseID':'C102','Title':'Advanced Machine Learning','Enrolled':40,'StartDate':'2025-03-15'},\n",
    "    {'CourseID':'C103','Title':'Data Visualization','Enrolled':75,'StartDate':'2025-02-20'},\n",
    "    {'CourseID':'C104','Title':'Intro to SQL','Enrolled':90,'StartDate':'2025-01-10'},\n",
    "    {'CourseID':'C105','Title':'Advanced Deep Learning','Enrolled':30,'StartDate':'2025-04-05'},\n",
    "    {'CourseID':'C106','Title':'Applied Statistics','Enrolled':60,'StartDate':'2025-03-01'},\n",
    "])\n",
    "\n",
    "# 1. Level creation using vectorized str.contains\n",
    "df_courses['Level'] = 'Intermediate'\n",
    "df_courses.loc[df_courses['Title'].str.contains('Intro'), 'Level'] = 'Beginner'\n",
    "df_courses.loc[df_courses['Title'].str.contains('Advanced'), 'Level'] = 'Advanced'\n",
    "\n",
    "# 2. StartMonth\n",
    "df_courses['StartDate'] = pd.to_datetime(df_courses['StartDate'])\n",
    "df_courses['StartMonth'] = df_courses['StartDate'].dt.month\n",
    "\n",
    "# 3. Average Enrolled per Level\n",
    "avg_enrolled = df_courses.groupby('Level', as_index=False)['Enrolled'].mean()\n",
    "\n",
    "print('--- Courses with Level and StartMonth ---')\n",
    "print(df_courses.to_string(index=False))\n",
    "print('\\n--- Average Enrolled per Level ---')\n",
    "print(avg_enrolled.to_string(index=False))\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
